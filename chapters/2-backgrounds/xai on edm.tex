\section{XAI on EDM}

Despite the critical relevance of explanations from predictive models, the literature on interpretability in EDM is relatively sparse. A recent review focusing on the prediction of student performance reveals that most studies have neglected to provide explanations when using non-transparent predictive models \cite{Chitti2020NeedPrediction}. This lack of attention to explanations was also documented in \cite{Livieris2023AnMining}. 

Among the studies that emphasize interpretability, the approaches vary. Most studies adopt pre-existing off-the-shelf tools to provide explanations, while others incorporate these tools as integral components for intervention purposes \cite{Mu2020TowardsStudents, Afzaal2021ExplainableSelf-Regulation}. For local explanations, widely employed tools include SHAP \cite{Livieris2023AnMining, Chiu2020GenderHypothesis, Doewes2020StructuralScoring, Oliveira2023TowardsEnglish} and LIME \cite{Livieris2023AnMining, Matetic2019MiningNetworks, Zabriskie2019UsingOutcomes, Hasib2022APerformance, Chen2022Week-WiseIntelligence}. In contrast, score-based metrics emerge as the predominant choice for global explanations. These metrics serve the dual objectives of identifying significant features for interventions and facilitating feature selection. Among the most frequently utilized measures are the MDI of tree-based models \cite{Cortez2008UsingPerformance, AshrafATechniques, Zhao2020PredictingData} and absolute average SHAP \cite{Hoq2023AnalysisCourse, Rohani2023EarlyMOOC}. Additionally, methods such as PDP \cite{Hong2022RandomSchool, Masci2018StudentApproach} and SHAP \cite{Chiu2020GenderHypothesis, Hoq2023AnalysisCourse} are commonly employed to visually illustrate the influence of individual features.

To the best of our knowledge, the ALE technique discussed and explored in this thesis as an alternative for explaining global feature contributions when data independence cannot be assumed, has not yet been widely employed in EDM. Only in \cite{NovilloRangone2022AutomationLearning}, where the authors presented a general framework for auto-ML, was ALE considered as one of the explainers that could be utilized in the interpretation step. However, specific details or examples of its use were not provided.

\subsection{Educational Assessment Discipline}

Educational Assessment refers to the discipline that aims to systematically evaluate student learning, skills, and performance to understand and improve educational outcomes. It encompasses a range of methods, but since the 1950s, quantitative analysis has been the standard procedure \cite{noah1969towards}. Moreover, a predominant data source is derived from the LSA tests. 

The LSA are standardized tests that collect, beyond student performance, much other information about the educational context in which the students are involved in. The LSAs thought standardizing psychometrics methodologies such as Item Response Theory (IRT) built a robust process for assessing the capabilities of students to learn what they were supposed to learn. Also, the periodicity of these tests enables temporal comparisons by observing the different paths that collected information might take across educational systems over time, making them a topic of interest among educators, researchers, and policymakers \cite{Johansson2016InternationalConsequences, Kaplan2021BayesianNAEP}.


Educational achievement is a multifactorial construct, influenced by a complex interplay of closely intertwined variables \cite{MartinezAbad2017Data-miningAchievement}. Within the EDM paradigm, a typical straightforward application of LSA data is a prediction function \(f(x) = y\), by which the contextual information \(X = (x^1, x^2, ..., x^n)\) collected by the LSA questionnaires and complemented by other sources are mapped to the LSA score \(Y\), a measure of educational achievement. This approach aligns with the concept of the education production function \cite{bowles1970towards, Scheerens1991ProcessEffectiveness}, where input contextual variables lead to educational outcomes.

In this framework, EDM can easily adapt to the large volume of data derived from modern LSA to optimize scientific discovery and enhance the debate surrounding practices in the field of education \cite{Gabriel2018ALiteracy, Gomes2020StudentBrazil,Martinez-Abad2020EducationalAssessment, Lezhnina2022CombiningPISA, Martinez-Abad2018BigEducation}. To identify and characterize the influence and interactions of factors related to educational achievement, high-performing supervised ML models and XAI can derive meaningful insights by understanding how \(F\) uses \(X\) to predict \(Y\) \cite{Chen2021SynergisticLiteracy, Dong2019AnApproaches, Gorostiaga2016OnSpain, Hu2022DiscoveryApproach, Martinez-Abad2020EducationalAssessment} 

Although inherent interpretable models are often used in this direction \cite{Adeodato2016DATADATAb, Martinez-Abad2020EducationalAssessment}  \cite{Gamazo2020AnTechniques}, many other scholars rely on explanations derived from opaque models. The tree-based algorithms such as random forest and gradient boosting are the most commonly used \cite{Gamazo2020AnTechniques} algorithm, and many scholars have relied on their intrinsically derived feature importance  \cite{Maia2021AssessingMethods, Rebai2020ATunisia, Masci2018StudentApproach, Lezhnina2022CombiningPISA, Chang2018ClusterEconomies, Martinez-Abad2019IdentificationApproach, Gabriel2018ALiteracy, Rodrigues2021DataExamination, KlcDepren2017IdentifyingTIMSS, Hu2022DiscoveryApproach, Chen2021SynergisticLiteracy}. The preference for the use of scores to characterize the relevance of features is also aligned with traditional studies that rely on coefficients of additive models. However, there is a growing trend towards employing post-hoc feature effects techniques, such as PDP and SHAP values, for a more detailed understanding of feature influences \cite{Lezhnina2022CombiningPISA, Masci2018StudentApproach, Rebai2020ATunisia, Schiltz2018UsingApproach}.


